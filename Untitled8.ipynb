{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mV2yCYB4no5-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install torchbnn==1.2.0\n",
        "!pip install blitz-bayesian-pytorch\n",
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "aiO2iUxhn4fy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images\n",
        "!mkdir /content/data\n",
        "!unzip -q breast-histopathology-images.zip -d /content/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQldXFpBn6Iq",
        "outputId": "71130093-b6f2-404c-83b7-2e755cbb32b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images\n",
            "License(s): CC0-1.0\n",
            "Downloading breast-histopathology-images.zip to /content\n",
            "100% 3.10G/3.10G [02:21<00:00, 23.2MB/s]\n",
            "100% 3.10G/3.10G [02:21<00:00, 23.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from blitz.modules import BayesianLinear\n",
        "from blitz.losses import kl_divergence_from_nn"
      ],
      "metadata": {
        "id": "vKh3NAAeoErZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Configuration\n",
        "data_dir = \"/content/data\"\n",
        "image_size = (50, 50)  # Sesuai dengan ukuran patch dataset\n",
        "batch_size = 32\n",
        "num_classes = 2  # IDC positif (1) dan negatif (0)\n",
        "num_epochs = 25\n",
        "kl_weight = 0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data Augmentation & Normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "# Custom Dataset Class\n",
        "class HistopathologyDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label\n",
        "# Load Dataset\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for root, _, files in os.walk(data_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".png\"):\n",
        "            try:\n",
        "                label = int(file.split(\"_class\")[-1].split(\".\")[0])\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "                labels.append(label)\n",
        "            except ValueError:\n",
        "                print(f\"Skipping invalid file: {file}\")\n",
        "\n",
        "if len(image_paths) == 0:\n",
        "    raise ValueError(\"No image files found in the specified directory. Check the dataset path.\")\n",
        "\n",
        "# Split Dataset\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, stratify=labels if len(set(labels)) > 1 else None, random_state=42\n",
        ")\n",
        "\n",
        "train_dataset = HistopathologyDataset(train_paths, train_labels, transform)\n",
        "val_dataset = HistopathologyDataset(val_paths, val_labels, transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "MqPbTU8JoFmK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bayesian AlexNet\n",
        "class BayesianAlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            BayesianLinear(256 * 6 * 6, 512), nn.ReLU(),\n",
        "            nn.Dropout(0.5), BayesianLinear(512, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Standard AlexNet (Non-Bayesian, No Dropout)\n",
        "class StandardAlexNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256 * 6 * 6, 512), nn.ReLU(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Initialize Models\n",
        "bayesian_model = BayesianAlexNet().to(device)\n",
        "standard_model = StandardAlexNet().to(device)\n",
        "\n",
        "# Loss & Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer_bayesian = optim.Adam(bayesian_model.parameters(), lr=0.001)\n",
        "optimizer_standard = optim.Adam(standard_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training Function\n",
        "def train_model(model, optimizer, is_bayesian=False):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        if is_bayesian:\n",
        "            loss += kl_weight * kl_divergence_from_nn(model)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        correct += outputs.argmax(dim=1).eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "    return running_loss/len(train_loader), 100. * correct / total\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss_b, train_acc_b = train_model(bayesian_model, optimizer_bayesian, True)\n",
        "    train_loss_s, train_acc_s = train_model(standard_model, optimizer_standard, False)\n",
        "    print(f\"Epoch {epoch+1}: Bayesian Acc: {train_acc_b:.2f}%, Standard Acc: {train_acc_s:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kEh3OB8om1s",
        "outputId": "fb534974-c8fa-4c01-da1c-1343d13ed52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Bayesian Acc: 80.05%, Standard Acc: 85.86%\n",
            "Epoch 2: Bayesian Acc: 78.27%, Standard Acc: 87.42%\n",
            "Epoch 3: Bayesian Acc: 78.63%, Standard Acc: 87.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisasi Hasil Akhir\n",
        "def plot_results(bayesian_acc, standard_acc):\n",
        "    plt.bar(['Bayesian', 'Standard'], [bayesian_acc, standard_acc])\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(\"Final Model Accuracy\")\n",
        "    plt.show()\n",
        "\n",
        "plot_results(train_acc_b, train_acc_s)"
      ],
      "metadata": {
        "id": "oX0OLtYeorpB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}